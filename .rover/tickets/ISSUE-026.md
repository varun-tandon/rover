# ISSUE-026: Description truncation to 200 characters lacks explanation

**Severity**: Medium
**Category**: Missing Why
**Detected by**: why-asker
**File**: `src/storage/issues.ts:204-211`

## Description

The code truncates issue descriptions to 200 characters before sending to the LLM, but there's no explanation of WHY 200 was chosen. This affects the quality of summarization - too short and context is lost, too long and tokens are wasted.

## Problematic Code

```typescript
const issueDetails = store.issues.map(issue => ({
  title: issue.title,
  file: issue.filePath,
  lines: issue.lineRange ? `${issue.lineRange.start}-${issue.lineRange.end}` : null,
  category: issue.category,
  description: issue.description.slice(0, 200) // Truncate long descriptions
}));
```

## Recommendation

Add a comment explaining the truncation: '// Truncate to 200 chars to balance context preservation with token efficiency. Testing showed 200 chars captures core issue details while keeping summarization costs reasonable for large issue sets.'

## Voting Summary

**Result**: 3/3 votes to approve

- **Voter 1**: Approved - "Genuine issue. The 200-character truncation at line 210 is a magic number with no explanation. Understanding why this specific value was chosen is important for maintainability - future developers might question whether it should be adjusted based on token costs, context needs, or LLM changes. The recommended comment adds valuable context about the tradeoff being made."
- **Voter 2**: Approved - "Genuine issue. The 200-character truncation on line 210 is a magic number with no explanation. Given that this affects LLM input quality and token costs, documenting why 200 was chosen (vs 100, 300, or no truncation) would help maintainers make informed decisions about adjusting this value. The severity is appropriate (medium) and the recommendation is reasonable."
- **Voter 3**: Approved - "The issue is genuine. The code at line 210 truncates descriptions to 200 characters without explanation. Since this directly impacts the quality of LLM summarization and involves a trade-off between context preservation and token costs, documenting the rationale is valuable. The recommendation is sensible and would improve code maintainability without causing harm."

---
*Generated by Rover on December 12, 2025*